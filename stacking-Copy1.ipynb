{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import catboost\n",
    "import lightgbm\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./custom_data/train_feature.csv\")\n",
    "test = pd.read_csv(\"./custom_data/test_feature.csv\")\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('problem', axis=1)\n",
    "y = train['problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X\n",
    "# y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\"logging_level\" : \"Silent\"}\n",
    "lgb_params = {'bagging_fraction': 0.9504775535991318, 'feature_fraction': 0.5598972214137229, 'lambda_l1': 2.9110070331408933, 'lambda_l2': 0.4065002276790508, 'learning_rate': 0.0118663823237834, 'max_depth': 12, 'min_child_samples': 19, 'min_child_weight': 35.21849812233922, 'min_samples_split': 0, 'min_split_gain': 0.05204638001792851, 'n_estimators': 949, 'num_leaves': 642, 'subsample': 0.5490080562116625}\n",
    "xgb_params = {'gamma': 8.712501813678685, 'max_depth': 22, 'min_child_weight': 9.863337491640031, 'n_estimators': 106, 'reg_alpha': 0.032974405578371495, 'reg_lambda': 0.0006919861676045414}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = []\n",
    "    models.append(catboost.CatBoostClassifier(**cat_params))\n",
    "    models.append(LGBMClassifier(**lgb_params))\n",
    "    models.append(xgb.XGBClassifier(**xgb_params))\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(ExtraTreesClassifier())\n",
    "    models.append(GradientBoostingClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(GaussianNB())\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    models.append(GaussianProcessClassifier())\n",
    "#     models.append(SVC(probability = True))\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, X_scaled, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    fscores = np.zeros((10, len(models)))\n",
    "    for total_idx, (train_ix, test_ix) in tqdm(enumerate(kfold.split(X))):\n",
    "        fold_yhats = list()\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_X_scaled, test_X_scaled = X_scaled[train_ix], X_scaled[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        \n",
    "        scores = []\n",
    "        for model_idx, model in enumerate(models):\n",
    "            if model_idx < 6: #####\n",
    "                model.fit(train_X, train_y)\n",
    "                yhat = model.predict_proba(test_X)\n",
    "                fold_yhats.append(yhat)\n",
    "                score = roc_auc_score(test_y, yhat[:, 1], average='micro')\n",
    "                fscores[total_idx, model_idx] = score\n",
    "            else:\n",
    "                model.fit(train_X_scaled, train_y)\n",
    "                yhat = model.predict_proba(test_X_scaled)\n",
    "                fold_yhats.append(yhat)\n",
    "                score = roc_auc_score(test_y, yhat[:, 1], average='micro')\n",
    "                fscores[total_idx, model_idx] = score                \n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y), fscores\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, X_scaled, y, models):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:\n",
    "            model.fit(X, y)\n",
    "        else:\n",
    "            model.fit(X_scaled, y)\n",
    " \n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, X_scaled, y, models):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:     \n",
    "            yhat = model.predict_proba(X)[:,1]\n",
    "            auc = roc_auc_score(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, auc*100))\n",
    "        else:\n",
    "            yhat = model.predict_proba(X_scaled)[:,1]\n",
    "            auc = roc_auc_score(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, auc*100))\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions(X, X_scaled, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:\n",
    "            yhat = model.predict_proba(X)\n",
    "            meta_X.append(yhat)\n",
    "        else:\n",
    "            yhat = model.predict_proba(X_scaled)\n",
    "            meta_X.append(yhat)\n",
    "    meta_X = hstack(meta_X)\n",
    "   # predict\n",
    "    return meta_model.predict_proba(meta_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:24:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [06:08, 368.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [12:23, 372.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:36:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [18:32, 370.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:42:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [24:42, 370.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:48:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [31:00, 373.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:55:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [37:20, 375.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [43:29, 373.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [49:37, 371.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:13:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [55:52, 372.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:19:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [1:01:59, 371.96s/it]\n"
     ]
    }
   ],
   "source": [
    "meta_X, meta_y, fscores = get_out_of_fold_predictions(X_train.values, X_scaled_train, y_train.values, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = fit_meta_model(meta_X, meta_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "status|cat|lgb|xgb|rf\n",
    ":---|:---:|:---:|:---:|:---:\n",
    "tuning X|0.83847134|0.83117312|0.83468733|0.82470269\n",
    "tuning O|----|0.83677207|0.832428|0.81877891\n",
    "tuning O, n = 500|----|----|0.82202676|0.81936112|\n",
    "tuning X, n = 100|----|----|----|----|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 데이터 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:26:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "fit_base_models(X_train, X_scaled_train ,y_train.values, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostClassifier: 83.982\n",
      "LGBMClassifier: 83.951\n",
      "XGBClassifier: 82.721\n",
      "RandomForestClassifier: 81.939\n",
      "ExtraTreesClassifier: 82.284\n",
      "GradientBoostingClassifier: 82.953\n",
      "KNeighborsClassifier: 75.251\n",
      "GaussianNB: 75.744\n",
      "LinearDiscriminantAnalysis: 79.454\n",
      "GaussianProcessClassifier: 69.138\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(X_test, X_scaled_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>lgbm</th>\n",
       "      <th>xgb</th>\n",
       "      <th>rf</th>\n",
       "      <th>et</th>\n",
       "      <th>gbc</th>\n",
       "      <th>knn</th>\n",
       "      <th>nb</th>\n",
       "      <th>lda</th>\n",
       "      <th>gpc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.850683</td>\n",
       "      <td>0.852576</td>\n",
       "      <td>0.832342</td>\n",
       "      <td>0.833518</td>\n",
       "      <td>0.828708</td>\n",
       "      <td>0.845880</td>\n",
       "      <td>0.740730</td>\n",
       "      <td>0.789133</td>\n",
       "      <td>0.801696</td>\n",
       "      <td>0.702000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.817521</td>\n",
       "      <td>0.816756</td>\n",
       "      <td>0.810055</td>\n",
       "      <td>0.801537</td>\n",
       "      <td>0.804823</td>\n",
       "      <td>0.804621</td>\n",
       "      <td>0.721297</td>\n",
       "      <td>0.745458</td>\n",
       "      <td>0.782696</td>\n",
       "      <td>0.687491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.847416</td>\n",
       "      <td>0.848379</td>\n",
       "      <td>0.844254</td>\n",
       "      <td>0.834084</td>\n",
       "      <td>0.832917</td>\n",
       "      <td>0.837638</td>\n",
       "      <td>0.741864</td>\n",
       "      <td>0.772099</td>\n",
       "      <td>0.728302</td>\n",
       "      <td>0.705674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.857766</td>\n",
       "      <td>0.853641</td>\n",
       "      <td>0.841624</td>\n",
       "      <td>0.840115</td>\n",
       "      <td>0.832015</td>\n",
       "      <td>0.844380</td>\n",
       "      <td>0.751396</td>\n",
       "      <td>0.762327</td>\n",
       "      <td>0.808420</td>\n",
       "      <td>0.721848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.844876</td>\n",
       "      <td>0.846916</td>\n",
       "      <td>0.826593</td>\n",
       "      <td>0.844960</td>\n",
       "      <td>0.851612</td>\n",
       "      <td>0.837347</td>\n",
       "      <td>0.764447</td>\n",
       "      <td>0.809588</td>\n",
       "      <td>0.815889</td>\n",
       "      <td>0.725219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.847067</td>\n",
       "      <td>0.843077</td>\n",
       "      <td>0.825959</td>\n",
       "      <td>0.820300</td>\n",
       "      <td>0.827807</td>\n",
       "      <td>0.840694</td>\n",
       "      <td>0.739894</td>\n",
       "      <td>0.757858</td>\n",
       "      <td>0.801014</td>\n",
       "      <td>0.684727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.828447</td>\n",
       "      <td>0.823175</td>\n",
       "      <td>0.813080</td>\n",
       "      <td>0.821847</td>\n",
       "      <td>0.824978</td>\n",
       "      <td>0.825350</td>\n",
       "      <td>0.746112</td>\n",
       "      <td>0.763760</td>\n",
       "      <td>0.801266</td>\n",
       "      <td>0.683247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.832283</td>\n",
       "      <td>0.831622</td>\n",
       "      <td>0.815158</td>\n",
       "      <td>0.817390</td>\n",
       "      <td>0.821615</td>\n",
       "      <td>0.825257</td>\n",
       "      <td>0.731330</td>\n",
       "      <td>0.751169</td>\n",
       "      <td>0.705707</td>\n",
       "      <td>0.702525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.856538</td>\n",
       "      <td>0.856346</td>\n",
       "      <td>0.847444</td>\n",
       "      <td>0.845537</td>\n",
       "      <td>0.837299</td>\n",
       "      <td>0.859845</td>\n",
       "      <td>0.753720</td>\n",
       "      <td>0.783430</td>\n",
       "      <td>0.806245</td>\n",
       "      <td>0.693538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.821685</td>\n",
       "      <td>0.825413</td>\n",
       "      <td>0.808336</td>\n",
       "      <td>0.803794</td>\n",
       "      <td>0.804480</td>\n",
       "      <td>0.817892</td>\n",
       "      <td>0.722582</td>\n",
       "      <td>0.743682</td>\n",
       "      <td>0.666563</td>\n",
       "      <td>0.678939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        cat      lgbm       xgb        rf        et       gbc       knn  \\\n",
       "0  0.850683  0.852576  0.832342  0.833518  0.828708  0.845880  0.740730   \n",
       "1  0.817521  0.816756  0.810055  0.801537  0.804823  0.804621  0.721297   \n",
       "2  0.847416  0.848379  0.844254  0.834084  0.832917  0.837638  0.741864   \n",
       "3  0.857766  0.853641  0.841624  0.840115  0.832015  0.844380  0.751396   \n",
       "4  0.844876  0.846916  0.826593  0.844960  0.851612  0.837347  0.764447   \n",
       "5  0.847067  0.843077  0.825959  0.820300  0.827807  0.840694  0.739894   \n",
       "6  0.828447  0.823175  0.813080  0.821847  0.824978  0.825350  0.746112   \n",
       "7  0.832283  0.831622  0.815158  0.817390  0.821615  0.825257  0.731330   \n",
       "8  0.856538  0.856346  0.847444  0.845537  0.837299  0.859845  0.753720   \n",
       "9  0.821685  0.825413  0.808336  0.803794  0.804480  0.817892  0.722582   \n",
       "\n",
       "         nb       lda       gpc  \n",
       "0  0.789133  0.801696  0.702000  \n",
       "1  0.745458  0.782696  0.687491  \n",
       "2  0.772099  0.728302  0.705674  \n",
       "3  0.762327  0.808420  0.721848  \n",
       "4  0.809588  0.815889  0.725219  \n",
       "5  0.757858  0.801014  0.684727  \n",
       "6  0.763760  0.801266  0.683247  \n",
       "7  0.751169  0.705707  0.702525  \n",
       "8  0.783430  0.806245  0.693538  \n",
       "9  0.743682  0.666563  0.678939  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fscores, columns=['cat', 'lgbm', 'xgb', 'rf', 'et', 'gbc', 'knn','nb','lda', 'gpc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8404283 , 0.83979015, 0.8264845 , 0.82630806, 0.82662555,\n",
       "       0.83389046, 0.7413372 , 0.76785042, 0.77177974, 0.69852076])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(fscores, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최대성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8436145322045181"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = super_learner_predictions(X_test, X_scaled_test, models, meta_model)\n",
    "roc_auc_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scaler = StandardScaler()\n",
    "X_scaled = new_scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = super_learner_predictions(test, test_scaled, models, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['problem'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission_0202_super_learner.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 7000.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_submission['problem'].apply(lambda x: round(x*10)).value_counts().sort_index().plot.bar()\n",
    "plt.ylim(0,7000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    11846\n",
       "1     3153\n",
       "Name: problem, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission['problem'].apply(lambda x: round(x*1)).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
