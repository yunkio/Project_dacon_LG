{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "from datetime import datetime, timedelta\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "import catboost\n",
    "import lightgbm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import hstack\n",
    "from numpy import vstack\n",
    "from numpy import asarray\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./custom_data/train_feature.csv\")\n",
    "test = pd.read_csv(\"./custom_data/test_feature.csv\")\n",
    "sample_submission = pd.read_csv('./data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop('problem', axis=1)\n",
    "y = train['problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X\n",
    "# y_train = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "X_scaled_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Super Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_params = {\"logging_level\" : \"Silent\"}\n",
    "lgb_params = {'bagging_fraction': 0.9504775535991318, 'feature_fraction': 0.5598972214137229, 'lambda_l1': 2.9110070331408933, 'lambda_l2': 0.4065002276790508, 'learning_rate': 0.0118663823237834, 'max_depth': 12, 'min_child_samples': 19, 'min_child_weight': 35.21849812233922, 'min_samples_split': 0, 'min_split_gain': 0.05204638001792851, 'n_estimators': 949, 'num_leaves': 642, 'subsample': 0.5490080562116625}\n",
    "xgb_params = {'gamma': 8.712501813678685, 'max_depth': 22, 'min_child_weight': 9.863337491640031, 'n_estimators': 106, 'num_boost_round': 165.69852832297272, 'reg_alpha': 0.032974405578371495, 'reg_lambda': 0.0006919861676045414}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models():\n",
    "    models = []\n",
    "    models.append(catboost.CatBoostClassifier(**cat_params))\n",
    "    models.append(LGBMClassifier(**lgb_params))\n",
    "    models.append(xgb.XGBClassifier(**xgb_params))\n",
    "    models.append(RandomForestClassifier())\n",
    "    models.append(ExtraTreesClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(GaussianNB())\n",
    "    models.append(GradientBoostingClassifier())\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(Lasso())\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect out of fold predictions form k-fold cross validation\n",
    "def get_out_of_fold_predictions(X, X_scaled, y, models):\n",
    "    meta_X, meta_y = list(), list()\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    fscores = np.zeros((10, len(models)))\n",
    "    for total_idx, (train_ix, test_ix) in tqdm(enumerate(kfold.split(X))):\n",
    "        fold_yhats = list()\n",
    "        train_X, test_X = X[train_ix], X[test_ix]\n",
    "        train_X_scaled, test_X_scaled = X_scaled[train_ix], X_scaled[test_ix]\n",
    "        train_y, test_y = y[train_ix], y[test_ix]\n",
    "        meta_y.extend(test_y)\n",
    "        \n",
    "        scores = []\n",
    "        for model_idx, model in enumerate(models):\n",
    "            if model_idx < 5:\n",
    "                model.fit(train_X, train_y)\n",
    "                yhat = model.predict_proba(test_X)\n",
    "                fold_yhats.append(yhat)\n",
    "                score = roc_auc_score(test_y, yhat[:, 1], average='micro')\n",
    "                fscores[total_idx, model_idx] = score\n",
    "            else:\n",
    "                model.fit(train_X_scaled, train_y)\n",
    "                yhat = model.predict_proba(test_X_scaled)\n",
    "                fold_yhats.append(yhat)\n",
    "                score = roc_auc_score(test_y, yhat[:, 1], average='micro')\n",
    "                fscores[total_idx, model_idx] = score                \n",
    "        meta_X.append(hstack(fold_yhats))\n",
    "    return vstack(meta_X), asarray(meta_y), fscores\n",
    " \n",
    "# fit all base models on the training dataset\n",
    "def fit_base_models(X, X_scaled, y, models):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:\n",
    "            model.fit(X, y)\n",
    "        else:\n",
    "            model.fit(X_scaled, y)\n",
    " \n",
    "# fit a meta model\n",
    "def fit_meta_model(X, y):\n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    " \n",
    "# evaluate a list of models on a dataset\n",
    "def evaluate_models(X, X_scaled, y, models):\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:     \n",
    "            yhat = model.predict_proba(X)[:,1]\n",
    "            auc = roc_auc_score(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, auc*100))\n",
    "        else:\n",
    "            yhat = model.predict_proba(X_scaled)[:,1]\n",
    "            auc = roc_auc_score(y, yhat)\n",
    "            print('%s: %.3f' % (model.__class__.__name__, auc*100))\n",
    "# make predictions with stacked model\n",
    "def super_learner_predictions(X, X_scaled, models, meta_model):\n",
    "    meta_X = list()\n",
    "    for model_idx, model in enumerate(models):\n",
    "        if model_idx < 4:\n",
    "            yhat = model.predict_proba(X)\n",
    "            meta_X.append(yhat)\n",
    "        else:\n",
    "            yhat = model.predict_proba(X_scaled)\n",
    "            meta_X.append(yhat)\n",
    "    meta_X = hstack(meta_X)\n",
    "   # predict\n",
    "    return meta_model.predict_proba(meta_X)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-638474c34c6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_models\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-83a88039712d>\u001b[0m in \u001b[0;36mget_models\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcatboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCatBoostClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcat_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mlgb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mxgb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb' is not defined"
     ]
    }
   ],
   "source": [
    "models = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_X, meta_y, fscores = get_out_of_fold_predictions(X_train.values, X_scaled_train, y_train.values, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = fit_meta_model(meta_X, meta_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "status|cat|lgb|xgb|rf\n",
    ":---|:---:|:---:|:---:|:---:\n",
    "tuning X|0.83847134|0.83117312|0.83468733|0.82470269\n",
    "tuning O|----|0.83677207|0.832428|0.81877891\n",
    "tuning O, n = 500|----|----|0.82202676|0.81936112|\n",
    "tuning X, n = 100|----|----|----|----|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전체 데이터 재학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_base_models(X_train, X_scaled_train ,y_train.values, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_models(X_test, X_scaled_test, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fscores, columns=['cat', 'lgbm', 'xgb', 'rf', 'et', 'knn','NB', 'gbt', 'lda', 'ridge', 'lasso'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(fscores, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최대성능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = super_learner_predictions(X_test, X_scaled_test, models, meta_model)\n",
    "roc_auc_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_scaler = StandardScaler()\n",
    "X_scaled = new_scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = super_learner_predictions(test, test_scaled, models, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['problem'] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission_0202_super_learner.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
